{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('../data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('../data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method (from fast.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0][:4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = images.view(-1, 28*28) #.cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.item()\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, sum_loss/total))\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)  #.cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).sum().item()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.45, 2.3269880920410158)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_model()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "model_accuracy_loss(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.6899\n",
      "Epoch [1/2], Loss: 0.5408\n",
      "Epoch [1/2], Loss: 0.4792\n",
      "Epoch [1/2], Loss: 0.4572\n",
      "Epoch [1/2], Loss: 0.4332\n",
      "Epoch [1/2], Loss: 0.4172\n",
      "Epoch [1/2], Loss: 0.4002\n",
      "Epoch [1/2], Loss: 0.3933\n",
      "Epoch [1/2], Loss: 0.3878\n",
      "Epoch [1/2], Loss: 0.3799\n",
      "Epoch [1/2], Loss: 0.3699\n",
      "Epoch [1/2], Loss: 0.3657\n",
      "Epoch [1/2], Loss: 0.3635\n",
      "Epoch [1/2], Loss: 0.3577\n",
      "Epoch [1/2], Loss: 0.3542\n",
      "Epoch [1/2], Loss: 0.3492\n",
      "Epoch [1/2], Loss: 0.3475\n",
      "Epoch [1/2], Loss: 0.3439\n",
      "Epoch [1/2], Loss: 0.3409\n",
      "Epoch [1/2], Valid Accuracy: 94.3100, Valid Loss: 0.2298\n",
      "Epoch [2/2], Loss: 0.3388\n",
      "Epoch [2/2], Loss: 0.3332\n",
      "Epoch [2/2], Loss: 0.3290\n",
      "Epoch [2/2], Loss: 0.3271\n",
      "Epoch [2/2], Loss: 0.3249\n",
      "Epoch [2/2], Loss: 0.3215\n",
      "Epoch [2/2], Loss: 0.3209\n",
      "Epoch [2/2], Loss: 0.3196\n",
      "Epoch [2/2], Loss: 0.3177\n",
      "Epoch [2/2], Loss: 0.3156\n",
      "Epoch [2/2], Loss: 0.3128\n",
      "Epoch [2/2], Loss: 0.3112\n",
      "Epoch [2/2], Loss: 0.3104\n",
      "Epoch [2/2], Loss: 0.3090\n",
      "Epoch [2/2], Loss: 0.3074\n",
      "Epoch [2/2], Loss: 0.3066\n",
      "Epoch [2/2], Loss: 0.3045\n",
      "Epoch [2/2], Loss: 0.3034\n",
      "Epoch [2/2], Loss: 0.3025\n",
      "Epoch [2/2], Valid Accuracy: 92.9100, Valid Loss: 0.2637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.91, 0.2637123618148267, 0.3025275804824817)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=2, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_model_v2(M = 300, p=0.1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.7507\n",
      "Epoch [1/4], Loss: 0.5892\n",
      "Epoch [1/4], Loss: 0.5339\n",
      "Epoch [1/4], Loss: 0.4990\n",
      "Epoch [1/4], Loss: 0.4751\n",
      "Epoch [1/4], Loss: 0.4612\n",
      "Epoch [1/4], Loss: 0.4505\n",
      "Epoch [1/4], Loss: 0.4462\n",
      "Epoch [1/4], Loss: 0.4442\n",
      "Epoch [1/4], Loss: 0.4399\n",
      "Epoch [1/4], Loss: 0.4339\n",
      "Epoch [1/4], Loss: 0.4302\n",
      "Epoch [1/4], Loss: 0.4255\n",
      "Epoch [1/4], Loss: 0.4224\n",
      "Epoch [1/4], Loss: 0.4210\n",
      "Epoch [1/4], Loss: 0.4171\n",
      "Epoch [1/4], Loss: 0.4129\n",
      "Epoch [1/4], Loss: 0.4087\n",
      "Epoch [1/4], Loss: 0.4047\n",
      "Epoch [1/4], Valid Accuracy: 92.9100, Valid Loss: 0.2830\n",
      "Epoch [2/4], Loss: 0.3978\n",
      "Epoch [2/4], Loss: 0.3898\n",
      "Epoch [2/4], Loss: 0.3853\n",
      "Epoch [2/4], Loss: 0.3786\n",
      "Epoch [2/4], Loss: 0.3742\n",
      "Epoch [2/4], Loss: 0.3685\n",
      "Epoch [2/4], Loss: 0.3654\n",
      "Epoch [2/4], Loss: 0.3603\n",
      "Epoch [2/4], Loss: 0.3554\n",
      "Epoch [2/4], Loss: 0.3531\n",
      "Epoch [2/4], Loss: 0.3509\n",
      "Epoch [2/4], Loss: 0.3481\n",
      "Epoch [2/4], Loss: 0.3468\n",
      "Epoch [2/4], Loss: 0.3446\n",
      "Epoch [2/4], Loss: 0.3442\n",
      "Epoch [2/4], Loss: 0.3406\n",
      "Epoch [2/4], Loss: 0.3390\n",
      "Epoch [2/4], Loss: 0.3380\n",
      "Epoch [2/4], Loss: 0.3374\n",
      "Epoch [2/4], Valid Accuracy: 92.3700, Valid Loss: 0.3183\n",
      "Epoch [3/4], Loss: 0.3353\n",
      "Epoch [3/4], Loss: 0.3330\n",
      "Epoch [3/4], Loss: 0.3312\n",
      "Epoch [3/4], Loss: 0.3297\n",
      "Epoch [3/4], Loss: 0.3278\n",
      "Epoch [3/4], Loss: 0.3268\n",
      "Epoch [3/4], Loss: 0.3249\n",
      "Epoch [3/4], Loss: 0.3241\n",
      "Epoch [3/4], Loss: 0.3226\n",
      "Epoch [3/4], Loss: 0.3214\n",
      "Epoch [3/4], Loss: 0.3202\n",
      "Epoch [3/4], Loss: 0.3186\n",
      "Epoch [3/4], Loss: 0.3169\n",
      "Epoch [3/4], Loss: 0.3155\n",
      "Epoch [3/4], Loss: 0.3140\n",
      "Epoch [3/4], Loss: 0.3134\n",
      "Epoch [3/4], Loss: 0.3131\n",
      "Epoch [3/4], Loss: 0.3121\n",
      "Epoch [3/4], Loss: 0.3115\n",
      "Epoch [3/4], Valid Accuracy: 93.8000, Valid Loss: 0.2480\n",
      "Epoch [4/4], Loss: 0.3098\n",
      "Epoch [4/4], Loss: 0.3077\n",
      "Epoch [4/4], Loss: 0.3067\n",
      "Epoch [4/4], Loss: 0.3055\n",
      "Epoch [4/4], Loss: 0.3041\n",
      "Epoch [4/4], Loss: 0.3035\n",
      "Epoch [4/4], Loss: 0.3023\n",
      "Epoch [4/4], Loss: 0.3013\n",
      "Epoch [4/4], Loss: 0.3004\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=4, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
